{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d25114",
   "metadata": {},
   "source": [
    "## Carregando embeddings e chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8b8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('variaveis_embeddings/embeddings_mat.pkl', 'rb') as f:\n",
    "    embeddings_mat = pickle.load(f)\n",
    "with open('variaveis_embeddings/embeddings_port.pkl', 'rb') as f:\n",
    "    embeddings_port = pickle.load(f)\n",
    "with open('variaveis_embeddings/chunks_mat.pkl', 'rb') as f:\n",
    "    chunks_mat = pickle.load(f)\n",
    "with open('variaveis_embeddings/chunks_port.pkl', 'rb') as f:\n",
    "    chunks_port = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57949f95",
   "metadata": {},
   "source": [
    "## Reduzindo Dimensionalidade (PCA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b19647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08555757 -0.19331195  0.06497455 ... -0.0657347  -0.02776902\n",
      "   0.03534328]\n",
      " [ 0.07595198 -0.17994625  0.12204586 ... -0.06843743  0.03015185\n",
      "   0.05021355]\n",
      " [ 0.10219311 -0.04988923  0.22471306 ...  0.01453297  0.03714858\n",
      "   0.02634114]\n",
      " ...\n",
      " [ 0.31093809  0.11143037 -0.04247366 ... -0.05224939  0.02923046\n",
      "   0.0054573 ]\n",
      " [ 0.33120463 -0.02168424  0.00551711 ... -0.0234345   0.021756\n",
      "  -0.02266387]\n",
      " [ 0.34626674  0.11101754 -0.20030809 ...  0.02186001 -0.00778661\n",
      "   0.02728312]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=64)\n",
    "\n",
    "embeddings_mat_port = np.vstack([embeddings_mat, embeddings_port])\n",
    "pca_mat_port = pca.fit_transform(embeddings_mat_port)\n",
    "\n",
    "print(pca_mat_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f3b9da",
   "metadata": {},
   "source": [
    "## Modelo de Classificação Binária (Pytorch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86096887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "binary_classifier = BinaryClassifier()\n",
    "print(binary_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae8911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 1/500, Loss: 0.6898\n",
      "Época: 2/500, Loss: 0.6727\n",
      "Época: 3/500, Loss: 0.6396\n",
      "Época: 4/500, Loss: 0.5779\n",
      "Época: 5/500, Loss: 0.4792\n",
      "Época: 6/500, Loss: 0.3564\n",
      "Época: 7/500, Loss: 0.2428\n",
      "Época: 8/500, Loss: 0.1581\n",
      "Época: 9/500, Loss: 0.1024\n",
      "Época: 10/500, Loss: 0.0690\n",
      "Época: 11/500, Loss: 0.0478\n",
      "Época: 12/500, Loss: 0.0353\n",
      "Época: 13/500, Loss: 0.0270\n",
      "Época: 14/500, Loss: 0.0212\n",
      "Época: 15/500, Loss: 0.0173\n",
      "Época: 16/500, Loss: 0.0143\n",
      "Época: 17/500, Loss: 0.0121\n",
      "Época: 18/500, Loss: 0.0103\n",
      "Época: 19/500, Loss: 0.0089\n",
      "Época: 20/500, Loss: 0.0078\n",
      "Época: 21/500, Loss: 0.0069\n",
      "Época: 22/500, Loss: 0.0061\n",
      "Época: 23/500, Loss: 0.0054\n",
      "Época: 24/500, Loss: 0.0049\n",
      "Época: 25/500, Loss: 0.0044\n",
      "Época: 26/500, Loss: 0.0040\n",
      "Época: 27/500, Loss: 0.0037\n",
      "Época: 28/500, Loss: 0.0034\n",
      "Época: 29/500, Loss: 0.0031\n",
      "Época: 30/500, Loss: 0.0029\n",
      "Época: 31/500, Loss: 0.0027\n",
      "Época: 32/500, Loss: 0.0025\n",
      "Época: 33/500, Loss: 0.0023\n",
      "Época: 34/500, Loss: 0.0022\n",
      "Época: 35/500, Loss: 0.0020\n",
      "Época: 36/500, Loss: 0.0019\n",
      "Época: 37/500, Loss: 0.0018\n",
      "Época: 38/500, Loss: 0.0017\n",
      "Época: 39/500, Loss: 0.0016\n",
      "Época: 40/500, Loss: 0.0015\n",
      "Época: 41/500, Loss: 0.0014\n",
      "Época: 42/500, Loss: 0.0013\n",
      "Época: 43/500, Loss: 0.0013\n",
      "Época: 44/500, Loss: 0.0012\n",
      "Época: 45/500, Loss: 0.0011\n",
      "Época: 46/500, Loss: 0.0011\n",
      "Época: 47/500, Loss: 0.0010\n",
      "Época: 48/500, Loss: 0.0010\n",
      "Época: 49/500, Loss: 0.0009\n",
      "Época: 50/500, Loss: 0.0009\n",
      "Época: 51/500, Loss: 0.0009\n",
      "Época: 52/500, Loss: 0.0008\n",
      "Época: 53/500, Loss: 0.0008\n",
      "Época: 54/500, Loss: 0.0008\n",
      "Época: 55/500, Loss: 0.0007\n",
      "Época: 56/500, Loss: 0.0007\n",
      "Época: 57/500, Loss: 0.0007\n",
      "Época: 58/500, Loss: 0.0007\n",
      "Época: 59/500, Loss: 0.0006\n",
      "Época: 60/500, Loss: 0.0006\n",
      "Época: 61/500, Loss: 0.0006\n",
      "Época: 62/500, Loss: 0.0006\n",
      "Época: 63/500, Loss: 0.0005\n",
      "Época: 64/500, Loss: 0.0005\n",
      "Época: 65/500, Loss: 0.0005\n",
      "Época: 66/500, Loss: 0.0005\n",
      "Época: 67/500, Loss: 0.0005\n",
      "Época: 68/500, Loss: 0.0005\n",
      "Época: 69/500, Loss: 0.0004\n",
      "Época: 70/500, Loss: 0.0004\n",
      "Época: 71/500, Loss: 0.0004\n",
      "Época: 72/500, Loss: 0.0004\n",
      "Época: 73/500, Loss: 0.0004\n",
      "Época: 74/500, Loss: 0.0004\n",
      "Época: 76/500, Loss: 0.0004\n",
      "Época: 77/500, Loss: 0.0003\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = torch.tensor(pca_mat_port, dtype=torch.float32)\n",
    "y = np.concatenate([np.ones(271), np.zeros(373)])\n",
    "Y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "modelo = binary_classifier\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=1e-3)\n",
    "\n",
    "epocas = 500\n",
    "early_stopping = 1e-5\n",
    "ultima_perda = None\n",
    "paciencia = 0\n",
    "\n",
    "for epoca in range(epocas):\n",
    "    modelo.train()\n",
    "    perda = 0\n",
    "    for batch_X, batch_y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = modelo(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        perda += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    perda_media_epoca = perda/len(dataset)\n",
    "    if ultima_perda is not None and ultima_perda - perda_media_epoca < early_stopping:\n",
    "        paciencia += 1\n",
    "        if paciencia == 5:\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Época: {epoca+1}/{epocas}, Loss: {perda_media_epoca:.4f}\")\n",
    "    ultima_perda = perda_media_epoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7801a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.tensor(pca_mat_port, dtype=torch.float32)\n",
    "y_test = y\n",
    "\n",
    "modelo.eval()\n",
    "with torch.no_grad():\n",
    "    outputs_test = modelo(X_test)\n",
    "    probs = outputs_test.squeeze().numpy()\n",
    "    eps = 1e-8\n",
    "    entropy = - (probs * np.log(probs + eps) + (1 - probs) * np.log(1 - probs + eps))\n",
    "\n",
    "\n",
    "indice_maior_duvida = np.argsort(-entropy)[0]\n",
    "print(indice_maior_duvida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fbd4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk com maior dúvida (mat):\n",
      "Samantha Onofre Lóssio \n",
      "Tibério Bezerra Soares\n",
      "Revisão Textual\n",
      "Aurea Suely Zavam\n",
      "Nukácia Meyre Araújo de Almeida\n",
      "Revisão Web\n",
      "Antônio Carlos Marques Júnior\n",
      "Débora Liberato Arruda Hissa\n",
      "Saulo Garcia\n",
      "Logística\n",
      "Francisco Roberto Dias de Aguiar\n",
      "Virgínia Ferreira Moreira\n",
      "Secretários\n",
      "Breno Giovanni Silva Araújo\n",
      "Francisca Venâncio da Silva\n",
      "Auxiliar\n",
      "Ana Paula Gomes Correia\n",
      "Bernardo Matias de Carvalho\n",
      "Charlene Oliveira da Silveira\n",
      "Isabella de Castro Britto\n",
      "Vivianny de Lima Santiago\n",
      "Wagner Souto Fernandes\n"
     ]
    }
   ],
   "source": [
    "idx = int(indice_maior_duvida)\n",
    "if idx < len(chunks_mat):\n",
    "    print(\"Chunk com maior dúvida (mat):\")\n",
    "    print(chunks_mat[idx].page_content)\n",
    "else:\n",
    "    print(\"Chunk com maior dúvida (port):\")\n",
    "    print(chunks_port[idx - len(chunks_mat)].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
